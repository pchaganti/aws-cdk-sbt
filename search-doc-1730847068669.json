{"searchDocs":[{"title":"POINT SOLUTION STUFF","type":0,"sectionRef":"#","url":"/sbt-aws/docs/point_solutions/intro","content":"POINT SOLUTION STUFF","keywords":"","version":"Next"},{"title":"Intent","type":0,"sectionRef":"#","url":"/sbt-aws/docs/point_solutions/token-vending-machine","content":"","keywords":"","version":"Next"},{"title":"High-level architecture​","type":1,"pageTitle":"Intent","url":"/sbt-aws/docs/point_solutions/token-vending-machine#high-level-architecture","content":" Provide a high level architecture for this patterns with diagrams and explanation  ","version":"Next","tagName":"h2"},{"title":"Implementation using AWS services​","type":1,"pageTitle":"Intent","url":"/sbt-aws/docs/point_solutions/token-vending-machine#implementation-using-aws-services","content":" Showcase sample implementation architecture using AWS services icons in the architecture diagram and provide explanation  ","version":"Next","tagName":"h2"},{"title":"Sample Code​","type":1,"pageTitle":"Intent","url":"/sbt-aws/docs/point_solutions/token-vending-machine#sample-code","content":" If there’s any sample code that you want to highlight, add it to this section - This is optional  GitHub repository  For a complete implementation of the sample architecture for this pattern, see the GitHub repository at * If there is a github repository for this pattern, provide a link to the repo  Blog references  Provide links to any blogs that you want to cross reference with this pattern - This is optional ","version":"Next","tagName":"h2"},{"title":"Tutorial Intro","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/intro","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Tutorial Intro","url":"/sbt-aws/docs/tutorials/intro#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"What you'll need​","type":1,"pageTitle":"Tutorial Intro","url":"/sbt-aws/docs/tutorials/intro#what-youll-need","content":" Node.js version 18.0 or above: When installing Node.js, you are recommended to check all checkboxes related to dependencies. AWS Cloud Development Kit version XX or above: Directions for installing are here  ","version":"Next","tagName":"h3"},{"title":"Step 1: CDK getting started​","type":1,"pageTitle":"Tutorial Intro","url":"/sbt-aws/docs/tutorials/intro#step-1-cdk-getting-started","content":" Follow the instructions in CDK's getting started guide. This guide walks you through installing the pre-requisites and ensuring your environment is prepared to build your first CDK app.  ","version":"Next","tagName":"h2"},{"title":"Step 2: Hello SBT!​","type":1,"pageTitle":"Tutorial Intro","url":"/sbt-aws/docs/tutorials/intro#step-2-hello-sbt","content":" Follow the instructions in Step One of CDK's &quot;Hello CDK&quot; project.  You don't have to build or deploy the project, just initialize a new empty project. Once done, come back here, and we'll get started with building your first SBT-enabled multi-tenant app. ","version":"Next","tagName":"h2"},{"title":"Build the control plane","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/build-it","content":"Build the control plane Now let's build and deploy this component. Before we do, we have to modify one other file. Open up the hello-cdk.ts file in the bin directory, and replace everything that's in there with the following contents: #!/usr/bin/env node import 'source-map-support/register'; import * as cdk from 'aws-cdk-lib'; import { ControlPlaneStack } from '../lib/control-plane'; // import { AppPlaneStack } from '../lib/app-plane'; const app = new cdk.App(); const controlPlaneStack = new ControlPlaneStack(app, 'ControlPlaneStack'); // const appPlaneStack = new AppPlaneStack(app, 'AppPlaneStack', { // eventManager: controlPlaneStack.eventManager, // }); Notice we're leaving a few lines commented out here, we'll come back to those later when we discuss the application plane. Ensure everything is saved, then from the root of your hello-cdk project, run the following: warning Because our control plane deploys Lambda functions, you'll need Docker installed to build and deploy this CDK stack npm run build cdk bootstrap cdk deploy ControlPlaneStack This will kick of the synthesis of your CDK application to AWS CloudFormation, then deploy that CloudFormation. Behind the scenes, a lot is getting created. This construct not only stands up the surface of our control plane API, using a new API Gateway component, it also deploys several services as AWS Lambda functions used for tenant provisioning and management. Feel free to open your AWS Console and take a look at the following (ensure you're in the same region you deployed to): AWS LambdaAmazon CognitoAPI Gateway Once done, we now have the left side of our conceptual diagram deployed, and we did it with just a few constructs. It deployed not only the API surface of our control plane, but also wired it up to EventBridge. Next, we'll start deploy the application plane, and connect it to the same EventBridge bus, so we can act upon those control plane messages.","keywords":"","version":"Next"},{"title":"Moesif API Monetization for AWS SBT","type":0,"sectionRef":"#","url":"/sbt-aws/docs/partners/isv-integrations/moesif","content":"","keywords":"","version":"Next"},{"title":"How it works​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#how-it-works","content":" ","version":"Next","tagName":"h2"},{"title":"Event Ingestion​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#event-ingestion","content":" The project deploys an Amazon Data Firehose to ingest your raw usage events. Events can be API Calls such as from an Amazon API Gateway instance or custom actions triggered within your application. The firehose will send all events to Moesif's Collection API for metering and analytics.    For more info on how the MoesifFirehoseConstruct works, view Moesif docs on ingesting actions via Firehose  ","version":"Next","tagName":"h3"},{"title":"User and Tenant Management​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#user-and-tenant-management","content":" The project also deploys a Lambda Function for user and tenant management. The lambda will listen to events like provisionSuccess to create companies and subscriptions in Moesif and your payment provider. Similarly, when receiving a deprovisionSuccess event, all subscriptions will be canceled for the tenant. You can inspect the code here.  SBT Entity\tMoesif Entity\tDescription\tParentTenant\tCompany\tYour customer that you provisioned resources for.\tNone Tenant\tSubscription\tA single subscription for a company/tenant.\tCompany User\tUser\tEnd users of your customer who login to your SaaS.\tCompany  ","version":"Next","tagName":"h3"},{"title":"How to use​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#how-to-use","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#prerequisites","content":" If you don't already have a SBT project deployed, follow AWS SBT's tutorial to deploy the sample hello-cdk project with a ControlPlane and CoreApplicationPlane.You already have a Moesif account. You can sign up for a trial on moesif.com  ","version":"Next","tagName":"h3"},{"title":"1. Install the NPM package​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#1-install-the-npm-package","content":" Within your SBT project directory, install sbt-aws-moesif via the following command:  npm install --save sbt-aws-moesif   ","version":"Next","tagName":"h3"},{"title":"2. Add MoesifBilling to your ControlPlane​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#2-add-moesifbilling-to-your-controlplane","content":" Instantiate the MoesifBilling construct like below. You will need to set some properties to authenticate with Moesif.  export class ControlPlaneStack extends Stack { public readonly regApiGatewayUrl: string; public readonly eventBusArn: string; constructor(scope: Construct, id: string, props: any) { super(scope, id, props); const cognitoAuth = new CognitoAuth(this, 'CognitoAuth', { idpName: 'COGNITO', systemAdminRoleName: 'SystemAdmin', systemAdminEmail: '&lt;&lt;Your Admin Email&gt;&gt;', }); const moesifBilling = new MoesifBilling(stack, 'MoesifBilling', { moesifApplicationId: '&lt;&lt;Your Moesif Application Id&gt;&gt;', moesifManagementAPIKey: '&lt;&lt;Your Moesif Management API Key&gt;&gt;', billingProviderSlug: BillingProviderSlug.STRIPE, billingProviderSecretKey: '&lt;&lt;Your Billing Provider\\'s Secret Such as for Stripe&gt;&gt;' } ); const controlPlane = new ControlPlane(this, 'ControlPlane', { auth: cognitoAuth, billing: moesifBilling, }); this.eventBusArn = controlPlane.eventBusArn; this.regApiGatewayUrl = controlPlane.controlPlaneAPIGatewayUrl; } }   ","version":"Next","tagName":"h3"},{"title":"Moesif Billing Properties​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#moesif-billing-properties","content":" Property Name\tType\tRequired\tDescription\tDefaultmoesifApplicationId\tstring\tRequired\tCollector Application Id from your Moesif account for event ingestion moesifManagementAPIKey\tstring\tRequired\tManagement API Key from your Moesif account. The key must have the following scopes: create:companies create:subscriptions create:users delete:companies delete:subscriptions delete:users moesifManagementAPIBaseUrl\tstring Override the base URL for the Moesif Mangaement API. For most setups, you don't need to set this.\thttps://api.moesif.com moesifCollectorAPIBaseUrl\tstring Override the base URL for the Moesif Collector API. For most setups, you don't need to set this.\thttps://api.moesif.net billingProviderSlug\tBillingProviderSlug\tRequired\tSlug for Billing Provider / Payment Gateway billingProviderSecretKey\tstring\tRequired\tSecret Key for Billing Provider / Payment Gateway selected by billingProviderSlug billingProviderClientId\tstring\tOnly if Zuora\tClient Id for Billing Provider / Payment Gateway. Only used when billingProviderSlug is Zuora billingProviderBaseUrl\tstring\tOnly if Chargebee or Zuora\tBase URL for Billing Provider / Payment Gateway. Only used when billingProviderSlug is Zuora or Chargebee tenantPlanField\tstring Tenant object's field name that contains the plan id used when creating new subscriptions. Only used when billingProviderSlug is Zuora\tplanId tenantPriceField\tstring Tenant object's field name that contains the price id used when creating new subscriptions.\tpriceId firehoseName\tstring The name of the Kinesis Firehose delivery stream. By default, a unique name will be generated. bucketName\tstring The name of the S3 bucket for backup. By default, a unique name will be generated. schema\tstring Moesif Event Schema for data ingestion. By default, Moesif actions\t  ","version":"Next","tagName":"h3"},{"title":"3. Provision a Tenant​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#3-provision-a-tenant","content":" Once you deploy your updated stack, create a tenant in your AWS SBT setup using the SBT APIs.  When you create a tenant, you must also set the price id to be used for creating subscriptions, By default, the field name is priceId, but this can be overridden via the above options. If you are using Zuora, you must also set the plan id. The field email must also be set.  If your provider is set to Zuora, you must also set these fields  If you're running the hello-cdk project, this can be done by running this script to onboard a new tenant. Modify, the script to also include the price (and plan if required).  To find your plan id and price id, you can log into Moesif UI and go to Product Catalog or log into your billing provider.  DATA=$(jq --null-input \\ --arg tenantEmail &quot;$TENANT_EMAIL&quot; \\ --arg tenantId &quot;$TENANT_ID&quot; \\ '{ &quot;email&quot;: $tenantEmail, &quot;tenantId&quot;: $tenantId, &quot;priceId&quot;: &quot;price_1MoBy5LkdIwHu7ixZhnattbh&quot; }') echo &quot;creating tenant...&quot; curl --request POST \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}tenants&quot; \\ --header &quot;Authorization: Bearer ${ID_TOKEN}&quot; \\ --header 'content-type: application/json' \\ --data &quot;$DATA&quot;   Once done, you should see the company show up in the Moesif UI. There should also be a subscription for the company in the &quot;active&quot; status.  The tenant will be subscribed to the price defined by defaultPriceId. This can be expanded to allow more customization.  ","version":"Next","tagName":"h3"},{"title":"4. Ingest Events​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#4-ingest-events","content":" Now that you created a tenant, you should ingest some actions in you're newly created firehose. Actions have an action name (like &quot;Signed Up&quot;, &quot;API Request&quot;, or &quot;Finished Job&quot;) which represents the usage event. You can also include arbitrary metadata with an action, which enables you to create billable metrics, usage reporting, and more. For more info, see docs on actions  You'll want to set a few fields like below:  action_name is a string and should include name of the event such as &quot;Processed Payment Transaction&quot;company_id is your tenant identifier. See companiestransaction_id should be a random UUID for this event which Moesif uses for deduplication. Docs on Moesif idempotency.request.time represents the transaction time as an ISO formatted string.metadata is an object which includes any custom properties for this event. By setting metadata, you can bill on arbitrary metrics, create metrics on them, etc. For example, if the action name is &quot;Processed Payment Transaction&quot;, you can include an amount and the currency to bill on the total amount.  For full schema and available fields, see Actions API Reference  An example action is below:  { &quot;action_name&quot;: &quot;Processed Payment Transaction&quot;, &quot;request&quot;: { &quot;time&quot;: &quot;2024-03-01T04:45:42.914&quot; }, &quot;company_id&quot;: &quot;12345&quot;, // This is your tenant id &quot;transaction_id&quot;: &quot;a3765025-46ec-45dd-bc83-b136c8d1d257&quot;, &quot;metadata&quot;: { &quot;amount&quot;: 24.6, &quot;currency&quot;: &quot;USD&quot;, &quot;time_seconds&quot;: 66.3 } }   In the above example, the action is created whenever a payment is processed. There are also two metrics we are tracking as part of the action (the amount of the payment and how long the job took). You can create billable metrics and usage reports from these attributes.  If your events are API calls, we recommend changing the MoesifEventSchema to API_CALL which provides a different schema than the above actions. See API Calls  ","version":"Next","tagName":"h3"},{"title":"5. Create a Billing Meter​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#5-create-a-billing-meter","content":" Now that the tenant is created, follow these steps to create a billing meter in Moesif. The billing meter can filter or aggregate on any of the metadata fields you included with your action.  You should also select the provider and price defined by billingProviderSlug and defaultPriceId.  ","version":"Next","tagName":"h3"},{"title":"Provider Specific Requirements​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#provider-specific-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Zuora​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#zuora","content":" If you are using Zuora, the following fields must be set when creating a new tenant:  { &quot;email&quot;: &quot;&lt;Customer email address&gt;&quot;, &quot;firstName&quot;: &quot;&lt;First name of customer contact&gt;&quot;, &quot;lastName&quot;: &quot;&lt;Last name of customer contact&gt;&quot;, &quot;currency&quot;: &quot;&lt;Three-letter ISO currency code&gt;&quot;, &quot;address&quot;: { &quot;state&quot;: &quot;&lt;State or providence of the contact's address&gt;&quot;, &quot;country&quot;: &quot;&lt;The country of the contact's address&gt;&quot; } }   ","version":"Next","tagName":"h3"},{"title":"Limitations​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#limitations","content":" sbt-aws-moesif is in preview. Development is still ongoing. There are limitations to be aware of.  Deprovisioning a tenant will cancel all subscriptions but does not delete objects in case a subscription should be reactivated.  ","version":"Next","tagName":"h2"},{"title":"Useful commands​","type":1,"pageTitle":"Moesif API Monetization for AWS SBT","url":"/sbt-aws/docs/partners/isv-integrations/moesif#useful-commands","content":" npm run build compile typescript to jsnpm run watch watch for changes and compilenpm run test perform the jest unit tests ","version":"Next","tagName":"h2"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/sbt-aws/docs/partners/isv-integrations/amberflo","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#prerequisites","content":" Deploy a SBT Project: If you don't already have a SBT project deployed, follow AWS SBT's tutorial to deploy the sample hello-cdk project with a ControlPlane and CoreApplicationPlane. Amberflo Account: You need an Amberflo account for this project. If you don’t have an Amberflo account, you can sign up for one here: Amberflo Signup. API Key Secret: After signing up, the Amberflo API Key must be stored as a secret in AWS Secrets Manager. The application by default expects the secret to be created with the name AmberfloApiKey. However, you can create a secret with your own custom name and pass it in as a parameter to AmberfloMetering. Secret Name: The name of the secret in AWS Secrets Manager Secret Key: The key within the secret JSON that contains the API Key  ","version":"Next","tagName":"h2"},{"title":"Obtaining the Plugin​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#obtaining-the-plugin","content":" Option 1: Clone the repository  git clone https://github.com/amberflo/sbt-aws-amberflo.git  Option 2: Download the latest release Visit the sbt-aws-amberflo releases and download the latest version.  ","version":"Next","tagName":"h2"},{"title":"Installation Steps​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#installation-steps","content":" Within your SBT project directory, install aws-sbt-amberflo via the following command:  npm install --save sbt-aws-amberflo    ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#configuration","content":" ","version":"Next","tagName":"h2"},{"title":"Add AmberfloMetering to Your Control Plane​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#add-amberflometering-to-your-control-plane","content":" Instantiate the AmberfloMetering construct in your AWS CDK stack. Here’s an example TypeScript code snippet:  import { Stack } from 'aws-cdk-lib'; import { Construct } from 'constructs'; import * as sbt from '@cdklabs/sbt-aws'; import { AmberfloMetering } from 'sbt-aws-amberflo'; export class ControlPlaneStack extends Stack { constructor(scope: Construct, id: string, props: any) { super(scope, id, props); const amberfloMetering = new AmberfloMetering(this, 'AmberfloMetering', { amberfloAPIKeySecretName: 'YourSecretName', amberfloAPIKeySecretId: 'YourSecretId', }); const controlPlane = new sbt.ControlPlane(this, 'ControlPlane', { metering: amberfloMetering, }); } }   ","version":"Next","tagName":"h3"},{"title":"Provision a Meter​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#provision-a-meter","content":" Once you deploy your updated stack, you can create and manage meters using the provided API endpoints. Here’s how you can create a meter:  METER=$(jq --null-input \\ '{ &quot;label&quot;: &quot;SBT Meter&quot;, &quot;meterApiName&quot;: &quot;sbt-meter&quot;, &quot;meterType&quot;: &quot;sum_of_all_usage&quot; }') echo &quot;creating meter...&quot; curl --request POST \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}meters&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --header 'content-type: application/json' \\ --data &quot;$METER&quot; | jq   The above 3 properties are the required properties for creating a meter. You can also pass in additional properties while creating a meter. See more on creating meters in Amberflo.  ","version":"Next","tagName":"h3"},{"title":"Update a Meter​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#update-a-meter","content":" Once you deploy your updated stack, you can update meters using the provided API endpoint. Here’s how you can update a meter:  UPDATE_METER=$(jq --null-input \\ '{ &quot;label&quot;: &quot;SBT trial meter&quot;, &quot;meterApiName&quot;: &quot;sbt-trial&quot;, &quot;meterType&quot;: &quot;sum_of_all_usage&quot; }') echo &quot;updating meter...&quot; curl --request PUT \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}meters/&lt;meter-id&gt;&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --header 'content-type: application/json' \\ --data &quot;$UPDATE_METER&quot; | jq   ","version":"Next","tagName":"h3"},{"title":"Get a Meter​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#get-a-meter","content":" You can get a meter by id using the provided API endpoint. Here’s how you can get a meter:  curl --request GET \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}meters/&lt;meterId&gt;&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --silent | jq   ","version":"Next","tagName":"h3"},{"title":"List all Meters​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#list-all-meters","content":" You can list all meters using the provided API endpoint. Here’s how you can list all meter:  curl --request GET \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}meters/&lt;meterId&gt;&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --silent | jq   ","version":"Next","tagName":"h3"},{"title":"Delete a Meter​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#delete-a-meter","content":" You can delete a meter by id using the provided API endpoint. Here’s how you can delete a meter:  curl --request DELETE \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}meters/&lt;meterId&gt;&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --silent | jq   ","version":"Next","tagName":"h3"},{"title":"Ingest Usage Events​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#ingest-usage-events","content":" To ingest usage events, application or service in the application plane must emit events that represent usage metrics, which will be processed by the ingestUsageEventFunction Lambda function.  Event details must contain the following required properties: ● tenantId: The identifier of the tenant to associate with the usage. ● meterApiName: The name of the meter as used in the createMeter. ● meterValue: The quantity or amount of usage to record for a tenant. These properties are necessary to accurately track and attribute usage metrics. You can also pass in additional values for dimensions, if the meter has dimensions defined.  Example  const putEventsResponse = eventManager.eventBus.putEvents({ entries: [{ detail: { &quot;tenantId&quot;: &lt;tenantId&gt;, &quot;meterApiName&quot;: &lt;meterApiName as used in create meter&gt;, &quot;meterValue&quot;: &lt;usage value that is to be recorded&gt; }, detailType: DetailType.INGEST_USAGE, source: eventManager.applicationPlaneEventSource, }], });   The ingestUsageEventFunction Lambda function will be triggered to handle this event and send the data to Amberflo for processing.  Note: the eventManager is the eventManager passed to the CoreApplicationPlane  ","version":"Next","tagName":"h3"},{"title":"Fetch Usage Data​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#fetch-usage-data","content":" To fetch usage data, use the API endpoint to retrieve data based on your meter API name: Example  METER_API_NAME = 'sbt-meter' START_TIME = 1724630400 END_TIME = 1724716800 curl --request GET \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}usage/&lt;meterId&gt;?meterApiName=${METER_API_NAME}&amp;startTimeInSeconds=${START_TIME}&amp;endTimeInSeconds=${END_TIME}&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --silent | jq   The meterApiName id not provided in the query string will be fetched using the meterId path parameter. The startTimeInSeconds and endTimeInSeconds are optional and default to (current time - 24hrs) and current time.  ","version":"Next","tagName":"h3"},{"title":"Canceling incorrect usage events​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#canceling-incorrect-usage-events","content":" There are occasions where a meter event source may send or report incorrect or erroneous meters. Amberflo provides the ability to cancel (undo) one or more meter events as needed. See detailed guide on canceling usage events. Example  FILTER=$(jq --null-input \\ '{ &quot;id&quot;: &quot;sbt-filtering-rule&quot;, &quot;meterApiName&quot;: &quot;sbt-trial&quot;, &quot;ingestionTimeRange&quot;: { &quot;startTimeInSeconds&quot;: 1724367600, &quot;endTimeInSeconds&quot;: 1724371200 } }') echo &quot;creating filtering rule for canceling usage events...&quot; curl --request DELETE \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}usage&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --header 'content-type: application/json' \\ --data &quot;$FILTER&quot; | jq   The id, meterApiName and ingestionTimeRange are required parameters. The above command creates a filtering rule that cancels the events for the meter sbt-trial in the given time range. You can also cancel more specific events for specific tenants or based on specific dimensions etc. See the Amberflo API for more details.  ","version":"Next","tagName":"h3"},{"title":"Usage Examples​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#usage-examples","content":" The Amberflo metering implementation provided in this repository allows ISVs to integrate Amberflo with their SBT-based applications. This enables ISVs to:  Track and analyze usage metrics for their tenantsCreate a more accurate and efficient billing process  The AmberfloMetering construct deploys an AWS Lambda function to handle usage metering. It also provides a set of APIs for creating and updating meters, fetching usage, as well as ingesting usage events and canceling usage events. SaaS admins can use these endpoints for managing the application metering. The following endpoints are created in the control plane  Create Meter: POST /meters Update Meter: PUT /meters/{meterId} Ingest Usage: POST /ingest Cancel Usage: DELETE /usage Fetch Usage: GET /usage/meterId   Here's a brief overview of how this works:  Meter Creation: SaaS admins can create meters through the create meter API in control plane or through the Amberflo UI.Event Emission: Your application or service emits an ingest usage event with the necessary details to measure usage for a specific meter.Lambda Invocation: The ingestUsageEventFunction of AmberfloMetering is invoked automatically upon receiving the event.Data Processing: The Lambda function processes the event data and sends it to Amberflo for recording and subsequent usage analysis.Fetch Usage: SaaS admins can fetch usage through the fetch usage API in control plane or through the Amberflo UI.  ","version":"Next","tagName":"h2"},{"title":"Contributing​","type":1,"pageTitle":"Introduction","url":"/sbt-aws/docs/partners/isv-integrations/amberflo#contributing","content":" We welcome contributions to improve the plugin! Please follow these steps:  Fork the Repository: Click the &quot;Fork&quot; button on the repository page to create your own copy.Create a Branch: Create a new branch for your feature or bug fix git checkout -b my-feature-branchMake Changes: Implement your feature or bug fix while adhering to existing coding standards.Write Tests: Add tests if applicable.Commit Your Changes: git commit -m &quot;Add feature X or fix issue Y&quot;Push to Your Fork: git push origin my-feature-branchSubmit a Pull Request: Open a pull request in the original repository with a clear description of your changes. ","version":"Next","tagName":"h2"},{"title":"Application plane utilities","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/app-plane-utils","content":"Application plane utilities Although entirely optional, SBT includes a utility that lets you define, and run arbitrary jobs upon receipt of a control plane message, called a ScriptJob. This mechanism is extended to produce two new helper constructs ProvisioningScriptJob and DeprovisioningScriptJob which are used for onboarding and off-boarding, respectively, in the reference architectures which were ported to SBT (see references at the end of this document). That tenant provisioning/deprovisioning process is depicted below: Notice the use of the provisioning.sh and deprovisioning.sh scripts at the top. These scripts are fed to the ProvisioningScriptJob and DeprovisioningScriptJob as parameters. Internally the ScriptJob launches an AWS CodeBuild project, wrapped inside an AWS Step Function, to execute the bash scripts. The ScriptJob also lets you specify what input variables to feed to the scripts, along with what output variables you expect them to return. Note that in this version of SBT, you can create the ScriptJob construct with ScriptJobProps and configure CoreAppPlane with ScriptJobs using its scriptJobs property. The CoreAppPlane will then link these ScriptJobs to EventBridge. Let's take a simple example: imagine our SaaS application deployed only a single S3 bucket per tenant. Let's create a ProvisioningScriptJob for that provisioning now: const scriptJobProps: TenantLifecycleScriptJobProps = { permissions: PolicyDocument.fromJson(/*See below*/), script: '' /*See below*/, environmentStringVariablesFromIncomingEvent: ['tenantId', 'tier'], environmentVariablesToOutgoingEvent: ['tenantS3Bucket', 'someOtherVariable', 'tenantConfig'], scriptEnvironmentVariables: { TEST: 'test', }, eventManager: eventManager /*See below on how to create EventManager*/, }; Key\tType\tPurposescript\tstring\tA string in bash script format that represents the job to be run (example below) permissions\tPolicyDocument\tAn IAM policy document giving this job the IAM permissions it needs to do what it's being asked to do environmentStringVariablesFromIncomingEvent\tstring[]\tThe environment variables to import into the ScriptJob from event details field. environmentVariablesToOutgoingEvent\tstring[]\tThe environment variables to export into the outgoing event once the ScriptJob has finished. scriptEnvironmentVariables\t{ [key: string]: string }\tThe variables to pass into the codebuild ScriptJob. eventManager\tIEventManager\tThe EventManager instance that allows connecting to events flowing between the Control Plane and other components. The heavy lifting of the ScriptJob construct (along with constructs that extend it like ProvisioningScriptJob) happens with the value of the script key. Let's take a look at the example provisioning script now: echo &quot;starting...&quot; # note that this template.json is being created here, but # it could just as easily be pulled in from an S3 bucket. cat &gt; template.json &lt;&lt; EOM { &quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;, &quot;Resources&quot;: {&quot;MyBucket&quot;: {&quot;Type&quot;: &quot;AWS::S3::Bucket&quot;}}, &quot;Outputs&quot;: {&quot;S3Bucket&quot;: {&quot;Value&quot;: { &quot;Ref&quot;: &quot;MyBucket&quot; }}} } EOM echo &quot;tenantId: $tenantId&quot; echo &quot;tier: $tier&quot; aws cloudformation create-stack --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; --template-body &quot;file://template.json&quot; aws cloudformation wait stack-create-complete --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; export tenantS3Bucket=$(aws cloudformation describe-stacks --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; | jq -r '.Stacks[0].Outputs[0].OutputValue') export someOtherVariable=&quot;this is a test&quot; echo $tenantS3Bucket export tenantConfig=$(jq --arg SAAS_APP_USERPOOL_ID &quot;MY_SAAS_APP_USERPOOL_ID&quot; \\ --arg SAAS_APP_CLIENT_ID &quot;MY_SAAS_APP_CLIENT_ID&quot; \\ --arg API_GATEWAY_URL &quot;MY_API_GATEWAY_URL&quot; \\ -n '{&quot;userPoolId&quot;:$SAAS_APP_USERPOOL_ID,&quot;appClientId&quot;:$SAAS_APP_CLIENT_ID,&quot;apiGatewayUrl&quot;:$API_GATEWAY_URL}') echo $tenantConfig export tenantStatus=&quot;created&quot; echo &quot;done!&quot; ","keywords":"","version":"Next"},{"title":"Congratulations!","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/congratulations","content":"Congratulations!","keywords":"","version":"Next"},{"title":"Create the application plane","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/create-application-plane","content":"Create the application plane As mentioned before, SBT is unopinionated about the application in which it's deployed. As a result, we expect you to create the ApplicationPlane construct as just another part of the CDK constructs that you'd use to define your application. Take this simple (non-functional) example: export interface AppPlaneProps extends cdk.StackProps { eventManager: sbt.IEventManager; } export class ApplicationPlaneStack extends Stack { constructor(scope: Construct, id: string, props: AppPlaneProps) { super(scope, id, props); new sbt.CoreApplicationPlane(this, 'CoreApplicationPlane', { eventManager: props.eventManager, scriptJobs: [], }); } } In this example we're creating the application plane of SBT, and passing in an EventManager created using the same EventBus that we used in our control plane. This will ensure that both planes are wired to the same events in Amazon EventBridge. What's missing in this example is the subscription to EventBridge events, and the acting upon those subscriptions. As an application plane developer, a builder could hook up listeners to the various events published by the control plane, and do what's asked in the event. For example, the onboarding event is sent by the control plane with the expectation that the application plane provisions new tenant resources. The event's payload should carry enough information for the application to complete its job. Once done, it's expected that the app plane sends back a status event indicating success or failure. Again, SBT allows builders to publish and subscribe directly to EventBridge, and does not attempt to interfere with that process. However, as part of the SBT library we've published a set of utilities to assist with typical application plane workflows. Let's look one of those utilities now. Once done, we'll come back to this code and fill it in with what we learned.","keywords":"","version":"Next"},{"title":"Install the SaaS Builder Toolkit for AWS","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/install-sbt","content":"Install the SaaS Builder Toolkit for AWS Now that you've initialized a new CDK app, let's install the SBT components. From within the hello-cdk directory, please run the following command: npm install @cdklabs/sbt-aws ","keywords":"","version":"Next"},{"title":"Create the control plane","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/create-control-plane","content":"Create the control plane Now that we have SBT installed, let's create a new SBT control plane. Create a new file under /lib/control-plane.ts with the following contents. warning Please be sure to replace the email address with a real email as this is where you'll get the temporary admin password. import * as sbt from '@cdklabs/sbt-aws'; import { Stack } from 'aws-cdk-lib'; import { Construct } from 'constructs'; export class ControlPlaneStack extends Stack { public readonly regApiGatewayUrl: string; public readonly eventManager: sbt.IEventManager; constructor(scope: Construct, id: string, props?: any) { super(scope, id, props); const cognitoAuth = new sbt.CognitoAuth(this, 'CognitoAuth', { // Avoid checking scopes for API endpoints. Done only for testing purposes. setAPIGWScopes: false, }); const controlPlane = new sbt.ControlPlane(this, 'ControlPlane', { auth: cognitoAuth, systemAdminEmail: 'ENTER YOUR EMAIL HERE', }); this.eventManager = controlPlane.eventManager; this.regApiGatewayUrl = controlPlane.controlPlaneAPIGatewayUrl; } } Notice here we're creating a new CDK Stack called &quot;ControlPlaneStack&quot;. In that stack, we're creating a ControlPlane construct which we imported from the @cdklabs/sbt-aws package. Another important concept worth pointing out here is the plugability of this approach. Notice we're creating an &quot;auth&quot; component, called &quot;CognitoAuth&quot;. This component implements the IAuth interface defined in the SBT core package. We currently have a Cognito implementation of IAuth, but we could technically implement that interface with any identity provider.","keywords":"","version":"Next"},{"title":"Provisioning script breakdown","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/provisioning-script-breakdown","content":"","keywords":"","version":"Next"},{"title":"CloudFormation template​","type":1,"pageTitle":"Provisioning script breakdown","url":"/sbt-aws/docs/tutorials/tutorial-basics/provisioning-script-breakdown#cloudformation-template","content":" Notice the first few lines contains a sample AWS CloudFormation template that contains our S3 Bucket.  # note that this template.json is being created here, but # it could just as easily be pulled in from an S3 bucket. cat &gt; template.json &lt;&lt; EOM { &quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;, &quot;Resources&quot;: {&quot;MyBucket&quot;: {&quot;Type&quot;: &quot;AWS::S3::Bucket&quot;}}, &quot;Outputs&quot;: {&quot;S3Bucket&quot;: {&quot;Value&quot;: { &quot;Ref&quot;: &quot;MyBucket&quot; }}} } EOM   In this case we're declaring it inline with the script, but as the comment points out, there's no reason this template couldn't live in an S3 bucket, or any other place supported by the CloudFormation SDK.  Next we're echoing the value of the tenantId and tier environment variables below the CloudFormation template.  ","version":"Next","tagName":"h2"},{"title":"Imported variables('environmentStringVariablesFromIncomingEvent')​","type":1,"pageTitle":"Provisioning script breakdown","url":"/sbt-aws/docs/tutorials/tutorial-basics/provisioning-script-breakdown#imported-variablesenvironmentstringvariablesfromincomingevent","content":" echo &quot;tenantId: $tenantId&quot; echo &quot;tier: $tier&quot;   Let's examine how exactly those variables get populated. Remember that the ScriptJob (which is used to extend the ProvisioningScriptJob construct) creates an AWS CodeBuild project internally. When the ScriptJob creates the CodeBuild project, it can specify what environment variables to provide. The ScriptJob utility is also triggered by an EventBridge message matching the criteria specified in the incomingEvent parameter of the ScriptJobProps. (You don't need to worry about doing that for ProvisioningScriptJob and DeprovisioningScriptJob because that is already configured.) The message that arrives via EventBridge has a detail JSON Object (see docs here) that carries with it contextual information included by the sender, in our case, the control plane. For each key in the environmentStringVariablesFromIncomingEvent object, the ScriptJob extracts the value of a matching key found in the EventBridge message's detail JSON object, and provides that value to the CodeBuild project as an environment variable.  So, take for example, this sample EventBridge provisioning message sent by a control plane:  { &quot;version&quot;: &quot;0&quot;, &quot;id&quot;: &quot;6a7e8feb-b491-4cf7-a9f1-bf3703467718&quot;, &quot;detail-type&quot;: &quot;onboardingRequest&quot;, &quot;source&quot;: &quot;controlPlaneEventSource&quot;, &quot;account&quot;: &quot;111122223333&quot;, &quot;time&quot;: &quot;2017-12-22T18:43:48Z&quot;, &quot;region&quot;: &quot;us-west-1&quot;, &quot;resources&quot;: [&quot;arn:aws:ec2:us-west-1:123456789012:instance/i-1234567890abcdef0&quot;], &quot;detail&quot;: { &quot;tenantId&quot;: &quot;e6878e03-ae2c-43ed-a863-08314487318b&quot;, &quot;tier&quot;: &quot;standard&quot; } }   When executing, the script cited above would echo both tenantId and tier with the values set according to this message.  ","version":"Next","tagName":"h2"},{"title":"Deploy tenant CloudFormation artifacts​","type":1,"pageTitle":"Provisioning script breakdown","url":"/sbt-aws/docs/tutorials/tutorial-basics/provisioning-script-breakdown#deploy-tenant-cloudformation-artifacts","content":" Next, we're deploying tenant infrastructure by way of the CloudFormation template we saw above.  aws cloudformation wait stack-create-complete --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot;   ","version":"Next","tagName":"h2"},{"title":"Exported variables ('environmentVariablesToOutgoingEvent')​","type":1,"pageTitle":"Provisioning script breakdown","url":"/sbt-aws/docs/tutorials/tutorial-basics/provisioning-script-breakdown#exported-variables-environmentvariablestooutgoingevent","content":" The final portion of the script exports environment variables containing information to return to the control plane via the outgoing EventBridge message.  export tenantS3Bucket=$(aws cloudformation describe-stacks --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; | jq -r '.Stacks[0].Outputs[0].OutputValue') export someOtherVariable=&quot;this is a test&quot; echo $tenantS3Bucket export tenantConfig=$(jq --arg SAAS_APP_USERPOOL_ID &quot;MY_SAAS_APP_USERPOOL_ID&quot; \\ --arg SAAS_APP_CLIENT_ID &quot;MY_SAAS_APP_CLIENT_ID&quot; \\ --arg API_GATEWAY_URL &quot;MY_API_GATEWAY_URL&quot; \\ -n '{&quot;userPoolId&quot;:$SAAS_APP_USERPOOL_ID,&quot;appClientId&quot;:$SAAS_APP_CLIENT_ID,&quot;apiGatewayUrl&quot;:$API_GATEWAY_URL}') echo $tenantConfig export tenantStatus=&quot;created&quot;   Similar to how it mapped incoming EventBridge message detail variables to environment variables, the ScriptJob does almost the same thing but in reverse. The variables specified in the environmentVariablesToOutgoingEvent section of ScriptJobProps will be extracted from the environment, and sent back in the EventBridge message's detail section. ","version":"Next","tagName":"h2"},{"title":"Testing the deployment","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/test-the-deployment","content":"Testing the deployment Once deployed, let's run a few tests to see our basic control plane and application plane in action. When you deployed the control plane, you should've received an email with temporary admin credentials. Let's use those credentials now to log in to that account. Please replace the placeholder ('INSERT PASSWORD HERE') with your temporary password in the script below. Once logged in, this script will onboard a new tenant, and retrieve its details. Note this script uses the jq JSON processor. PASSWORD='INSERT PASSWORD HERE' # Change this to a real email if you'd like to log into the tenant TENANT_EMAIL=&quot;tenant@example.com&quot; CONTROL_PLANE_STACK_NAME=&quot;ControlPlaneStack&quot; TENANT_NAME=&quot;tenant$RANDOM&quot; CLIENT_ID=$(aws cloudformation describe-stacks \\ --stack-name &quot;$CONTROL_PLANE_STACK_NAME&quot; \\ --query &quot;Stacks[0].Outputs[?OutputKey=='ControlPlaneIdpClientId'].OutputValue&quot; \\ --output text) USER_POOL_ID=$(aws cloudformation describe-stacks \\ --stack-name &quot;$CONTROL_PLANE_STACK_NAME&quot; \\ --query &quot;Stacks[0].Outputs[?OutputKey=='ControlPlaneIdpUserPoolId'].OutputValue&quot; \\ --output text) USER=&quot;admin&quot; # required in order to initiate-auth aws cognito-idp update-user-pool-client \\ --user-pool-id &quot;$USER_POOL_ID&quot; \\ --client-id &quot;$CLIENT_ID&quot; \\ --explicit-auth-flows USER_PASSWORD_AUTH # remove need for password reset aws cognito-idp admin-set-user-password \\ --user-pool-id &quot;$USER_POOL_ID&quot; \\ --username &quot;$USER&quot; \\ --password &quot;$PASSWORD&quot; \\ --permanent # get credentials for user AUTHENTICATION_RESULT=$(aws cognito-idp initiate-auth \\ --auth-flow USER_PASSWORD_AUTH \\ --client-id &quot;${CLIENT_ID}&quot; \\ --auth-parameters &quot;USERNAME='${USER}',PASSWORD='${PASSWORD}'&quot; \\ --query 'AuthenticationResult') ACCESS_TOKEN=$(echo &quot;$AUTHENTICATION_RESULT&quot; | jq -r '.AccessToken') CONTROL_PLANE_API_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name &quot;$CONTROL_PLANE_STACK_NAME&quot; \\ --query &quot;Stacks[0].Outputs[?contains(OutputKey,'controlPlaneAPIEndpoint')].OutputValue&quot; \\ --output text) DATA=$(jq --null-input \\ --arg tenantName &quot;$TENANT_NAME&quot; \\ --arg tenantEmail &quot;$TENANT_EMAIL&quot; \\ '{ &quot;tenantName&quot;: $tenantName, &quot;email&quot;: $tenantEmail, &quot;tier&quot;: &quot;basic&quot;, &quot;tenantStatus&quot;: &quot;In progress&quot; }') echo &quot;creating tenant...&quot; curl --request POST \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}tenants&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --header 'content-type: application/json' \\ --data &quot;$DATA&quot; | jq echo &quot;&quot; # add newline echo &quot;retrieving tenants...&quot; curl --request GET \\ --url &quot;${CONTROL_PLANE_API_ENDPOINT}tenants&quot; \\ --header &quot;Authorization: Bearer ${ACCESS_TOKEN}&quot; \\ --silent | jq Now that we've onboarded a tenant, let's take a look at the console to see what got deployed. First, let's open the DynamoDB console. Once open, click the Explore Items link on the left. On the &quot;Tables&quot; screen, select the table that starts with ControlPlaneStack. Notice there is an entry for the tenant we just onboarded. Also notice it's probably still &quot;in progress&quot; Recall that we deployed a ScriptJob with our application plane, and it's a wrapper around an AWS Step Function that runs our provisioning script via CodeBuild. Let's take a look at that Step Function now by clicking navigating to Step Functions in the console (ensure you're in the same region you deployed to). The Step Function is likely still running, but feel free to examine the execution. Once finished, it'll return the results back to EventBridge, and close the loop with the Control plane.","keywords":"","version":"Next"},{"title":"Putting it all together","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-basics/putting-it-all-together","content":"Putting it all together Now that we've seen the various parts of the application plane in isolation, let's put it all together. Please create the following file in the /lib directory of your CDK app and name it app-plane.ts. Now open that file and paste the following contents into it: import * as sbt from '@cdklabs/sbt-aws'; import * as cdk from 'aws-cdk-lib'; import { EventBus } from 'aws-cdk-lib/aws-events'; import { PolicyDocument, PolicyStatement, Effect } from 'aws-cdk-lib/aws-iam'; export interface AppPlaneProps extends cdk.StackProps { eventManager: sbt.IEventManager; } export class AppPlaneStack extends cdk.Stack { constructor(scope: cdk.App, id: string, props: AppPlaneProps) { super(scope, id, props); const provisioningScriptJobProps: sbt.TenantLifecycleScriptJobProps = { permissions: new PolicyDocument({ statements: [ new PolicyStatement({ actions: [ 'cloudformation:CreateStack', 'cloudformation:DescribeStacks', 's3:CreateBucket', ], resources: ['*'], effect: Effect.ALLOW, }), ], }), script: ` echo &quot;starting...&quot; # note that this template.yaml is being created here, but # it could just as easily be pulled in from an S3 bucket. cat &gt; template.json &lt;&lt; EndOfMessage { &quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;, &quot;Resources&quot;: { &quot;MyBucket&quot;:{ &quot;Type&quot;: &quot;AWS::S3::Bucket&quot; }}, &quot;Outputs&quot;: { &quot;S3Bucket&quot;: { &quot;Value&quot;: { &quot;Ref&quot;: &quot;MyBucket&quot; }}} } EndOfMessage echo &quot;tenantId: $tenantId&quot; echo &quot;tier: $tier&quot; aws cloudformation create-stack --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; --template-body &quot;file://template.json&quot; aws cloudformation wait stack-create-complete --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; export tenantS3Bucket=$(aws cloudformation describe-stacks --stack-name &quot;tenantTemplateStack-\\${tenantId}&quot; | jq -r '.Stacks[0].Outputs[0].OutputValue') export someOtherVariable=&quot;this is a test&quot; echo $tenantS3Bucket export tenantConfig=$(jq --arg SAAS_APP_USERPOOL_ID &quot;MY_SAAS_APP_USERPOOL_ID&quot; \\ --arg SAAS_APP_CLIENT_ID &quot;MY_SAAS_APP_CLIENT_ID&quot; \\ --arg API_GATEWAY_URL &quot;MY_API_GATEWAY_URL&quot; \\ -n '{&quot;userPoolId&quot;:$SAAS_APP_USERPOOL_ID,&quot;appClientId&quot;:$SAAS_APP_CLIENT_ID,&quot;apiGatewayUrl&quot;:$API_GATEWAY_URL}') echo $tenantConfig export tenantStatus=&quot;created&quot; echo &quot;done!&quot; `, environmentStringVariablesFromIncomingEvent: ['tenantId', 'tier'], environmentVariablesToOutgoingEvent: [ 'tenantS3Bucket', 'someOtherVariable', 'tenantConfig', 'tenantStatus', ], scriptEnvironmentVariables: { TEST: 'test', }, eventManager: props.eventManager, }; const provisioningJobScript: sbt.ProvisioningScriptJob = new sbt.ProvisioningScriptJob( this, 'provisioningJobScript', provisioningScriptJobProps ); new sbt.CoreApplicationPlane(this, 'CoreApplicationPlane', { eventManager: eventManager, scriptJobs: [provisioningJobScript], }); } } Although this looks like a lot of code, it's still very few constructs. Now that we've defined our app plane, let's again open up the hello-cdk.ts file in the bin directory of your CDK app. Once open, uncomment each commented line. The final file should look like this: #!/usr/bin/env node import 'source-map-support/register'; import * as cdk from 'aws-cdk-lib'; import { ControlPlaneStack } from '../lib/control-plane'; import { AppPlaneStack } from '../lib/app-plane'; const app = new cdk.App(); const controlPlaneStack = new ControlPlaneStack(app, 'ControlPlaneStack'); const appPlaneStack = new AppPlaneStack(app, 'AppPlaneStack', { eventManager: controlPlaneStack.eventManager, }); Once done, ensure all files are saved, and let's deploy the solution again, but this time we'll include the application plane: npm run build cdk deploy ControlPlaneStack AppPlaneStack ","keywords":"","version":"Next"},{"title":"Manage Docs Versions","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-extras/manage-docs-versions","content":"","keywords":"","version":"Next"},{"title":"Create a docs version​","type":1,"pageTitle":"Manage Docs Versions","url":"/sbt-aws/docs/tutorials/tutorial-extras/manage-docs-versions#create-a-docs-version","content":" Release a version 1.0 of your project:  npm run docusaurus docs:version 1.0   The docs folder is copied into versioned_docs/version-1.0 and versions.json is created.  Your docs now have 2 versions:  1.0 at http://localhost:3000/docs/ for the version 1.0 docscurrent at http://localhost:3000/docs/next/ for the upcoming, unreleased docs  ","version":"Next","tagName":"h2"},{"title":"Add a Version Dropdown​","type":1,"pageTitle":"Manage Docs Versions","url":"/sbt-aws/docs/tutorials/tutorial-extras/manage-docs-versions#add-a-version-dropdown","content":" To navigate seamlessly across versions, add a version dropdown.  Modify the docusaurus.config.js file:  docusaurus.config.js export default { themeConfig: { navbar: { items: [ { type: 'docsVersionDropdown', }, ], }, }, };   The docs version dropdown appears in your navbar:    ","version":"Next","tagName":"h2"},{"title":"Update an existing version​","type":1,"pageTitle":"Manage Docs Versions","url":"/sbt-aws/docs/tutorials/tutorial-extras/manage-docs-versions#update-an-existing-version","content":" It is possible to edit versioned docs in their respective folder:  versioned_docs/version-1.0/hello.md updates http://localhost:3000/docs/hellodocs/hello.md updates http://localhost:3000/docs/next/hello ","version":"Next","tagName":"h2"},{"title":"Translate your site","type":0,"sectionRef":"#","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site","content":"","keywords":"","version":"Next"},{"title":"Configure i18n​","type":1,"pageTitle":"Translate your site","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site#configure-i18n","content":" Modify docusaurus.config.js to add support for the fr locale:  docusaurus.config.js export default { i18n: { defaultLocale: 'en', locales: ['en', 'fr'], }, };   ","version":"Next","tagName":"h2"},{"title":"Translate a doc​","type":1,"pageTitle":"Translate your site","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site#translate-a-doc","content":" Copy the docs/intro.md file to the i18n/fr folder:  mkdir -p i18n/fr/docusaurus-plugin-content-docs/current/ cp docs/intro.md i18n/fr/docusaurus-plugin-content-docs/current/intro.md   Translate i18n/fr/docusaurus-plugin-content-docs/current/intro.md in French.  ","version":"Next","tagName":"h2"},{"title":"Start your localized site​","type":1,"pageTitle":"Translate your site","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site#start-your-localized-site","content":" Start your site on the French locale:  npm run start -- --locale fr   Your localized site is accessible at http://localhost:3000/fr/ and the Getting Started page is translated.  caution In development, you can only use one locale at a time.  ","version":"Next","tagName":"h2"},{"title":"Add a Locale Dropdown​","type":1,"pageTitle":"Translate your site","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site#add-a-locale-dropdown","content":" To navigate seamlessly across languages, add a locale dropdown.  Modify the docusaurus.config.js file:  docusaurus.config.js export default { themeConfig: { navbar: { items: [ { type: 'localeDropdown', }, ], }, }, };   The locale dropdown now appears in your navbar:    ","version":"Next","tagName":"h2"},{"title":"Build your localized site​","type":1,"pageTitle":"Translate your site","url":"/sbt-aws/docs/tutorials/tutorial-extras/translate-your-site#build-your-localized-site","content":" Build your site for a specific locale:  npm run build -- --locale fr   Or build your site to include all the locales at once:  npm run build  ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}